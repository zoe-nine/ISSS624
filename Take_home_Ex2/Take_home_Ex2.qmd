---
title: "Take_home_Ex2"
editor: visual
execute: 
  warning: false
  message: false
---

## Overview

This take-home exercise 2 aims to complete the following tasks:

-   Using appropriate sf method, import the shapefile into R and save it in a simple feature data frame format.

-   Using appropriate tidyr and dplyr methods, derive the proportion of functional andnon-functional water point at LGA level (i.e. ADM2).

-   Combining the geospatial and aspatial data frame into simple feature data frame.

-   Delineating water point measures functional regions by using conventional hierarchical clustering.

-   Delineating water point measures functional regions by using spatially constrained clustering algorithms.

## Getting Started

In the code chunk below, `p_load()` of *pacman* package is used to install and load the following R packages into R environment:

-   sf: for importing, managing, and processing geospatial data

-   tidyverse: for performing data science tasks such as importing, wrangling and visualising data

-   tmap: for plotting choropleth map to show the distribution

-   spdep: for computing Global and Local Measure of Spatial Autocorrelation (GLSA)

-   funModeling: for rapid Exploratory Data Analysis

```{r}
pacman::p_load(tmap, sf, tidyverse, spdep, funModeling, ClustGeo, 
               ggpubr, cluster, factoextra, NbClust,
               heatmaply, corrplot, psych, tidyverse,
               plotly, ggdendro, GGally)
```

## Data Import

In this in-class exercise, two data sets will be used. They are:

-   geo_export (data from WPdx Global Data Repositories)
-   geoBoundaries-NGA-ADM2 (Nigeria Level-2 Administrative Boundary, also known as Local Government Area, polygon features GIS data)

### Importing water point data

The code chunk below imports the water point data into R environment. Instead of using `read.csv()` of Base R to import the csv file into R, `read_csv()` of **readr** package is used. This is because during the initial data exploration, we notice that there is at least one field name with space between the field name (ie. *New Georeferenced Column*).

Also, as we are interested on water point in Nigeria in this study, `filter()` of **dplyr** is used to extract out records belong to Nigeria only.

```{r}
#| eval: false
wp_nga <- read_csv("geodata/WPdx.csv") %>%
  filter(`#clean_country_name` == "Nigeria")
```

#### Convert wkt data

After the data are imported into R environment, we need to review both the data structure and the data table if it is in tibble data frame format in R Studio. Notice that the newly imported tibble data frame (i.e. wp_nga) contains a field called *New Georeferenced Column* which represent spatial data in a textual format. In fact, this kind of text file is popularly known as **Well Known Text** in short **wkt**.

Two steps will be used to convert an aspatial data file in wkt format into a sf data frame by using sf.

First, `st_as_sfc()` of sf package is used to derive a new field called *Geometry* as shown in the code chunk below.

```{r}
#| eval: false
wp_nga$Geometry = st_as_sfc(wp_nga$`New Georeferenced Column`)
```

Next, `st_sf()` will be used to convert the tibble data frame into sf data frame and a new sf data frame called *wp_sf* will be created.

```{r}
#| eval: false
wp_sf <- st_sf(wp_nga, crs=4326) 
```

### Importing Nigeria LGA level boundary data

For the purpose of this exercise, shapefile downloaded from [geoBoundaries](https://www.geoboundaries.org/) portal will be used.

```{r}
#| eval: false
nga <- st_read(dsn = "geodata",
               layer = "geoBoundaries-NGA-ADM2",
               crs = 4326) %>%
  select(shapeName)
```

### **Checking of duplicated area name (reference taken from Jordan)** 

Firstly, we will order our dataframe by alphabetical order based on the shapeName. We will then use the `duplicated` function to retrieve all the shapeName that has duplicates and store it in a list. From the result below, we identified **12** shapeNames that are duplicates.

```{r}
#| eval: false
nga<- (nga[order(nga$shapeName), ])
duplicate_area <- nga$shapeName[nga$shapeName %in% nga$shapeName[duplicated(nga$shapeName)] ]
duplicate_area
```

Through the use of Google, we are able to retrieve the actual name and state of the areas. Then we will access the individual index of the `nigeria` data frame and change the value. Lastly, we use the [`length()`](https://rdrr.io/r/base/length.html) function to ensure there is no more duplicated shapeName.

```{r}
#| eval: false
nga$shapeName[c(94,95,304,305,355,356,519,546,547,693,694)] <- c(
  "Bassa (Kogi)","Bassa (Plateau)",
  "Ifelodun (Kwara)","Ifelodun (Osun)",
  "Irepodun (Kwara)","Irepodun (Osun)",
  "Nassarawa","Obi (Benue)","Obi(Nasarawa)",
  "Surulere (Lagos)","Surulere (Oyo)")

length((nga$shapeName[nga$shapeName %in% nga$shapeName[duplicated(nga$shapeName)] ]))
```

## Point in Polygon Overlay

The code chunk below use a geoprocessing function (or commonly know as GIS analysis) called **point-in-polygon overlay** to transfer the attribute information in *nga* sf data frame into *wp_sf* data frame.

```{r}
#| eval: false
wp_sf <- st_join(wp_sf, nga)
```

## Data Wrangling

### Recoding NA values into string

In the code chunk below, `replace_na()` is used to recode all the *NA* values in *status_clean, water_tech_category* fields into *Unknown*.

```{r}
#| eval: false
wp_sf <- wp_sf %>%
  mutate(`#status_clean`= replace_na(`#status_clean`, "Unknown")) %>%
  mutate(`#water_tech_category`= replace_na(`#water_tech_category`, "Unknown"))
```

### Extracting functional water point

In the code chunk below, `filter()` of dplyr is used to select functional water points.

```{r}
#| eval: false
wpt_functional <- wp_sf %>%
  filter(`#status_clean` %in%
           c("Functional", 
             "Functional but not in use",
             "Functional but needs repair"))
```

### Extracting non-functional water point

In the code chunk below, `filter()` of dplyr is used to select non-functional water points.

```{r}
#| eval: false
wpt_nonfunctional <- wp_sf %>%
  filter(`#status_clean` %in%
           c("Abandoned/Decommissioned", 
             "Abandoned",
             "Non-Functional",
             "Non functional due to dry season",
             "Non-Functional due to dry season"))
```

### Extracting water point with Unknown class

In the code chunk below, `filter()` of dplyr is used to select water points with unknown status.

```{r}
#| eval: false
wpt_unknown <- wp_sf %>%
  filter(`#status_clean` == "Unknown")
```

### Extracting main water point technology

The code chunk below plots a distribution of water technology categories so that the main water point technology would be selected and technology with lower proportion would be discarded.

```{r}
#| eval: false
freq(data=wp_sf, 
     input = '#water_tech_category')
```

![](images/Screenshot%202022-12-09%20at%2011.18.40%20PM.png)

In the code chunk below, `filter()` of dplyr is used to select main water point technology (hand pump and mechanized pump).

```{r}
#| eval: false
wpt_handbump <- wp_sf %>%
  filter(`#water_tech_category` == "Hand Pump")
```

```{r}
#| eval: false
wpt_mechanisdpump <- wp_sf %>%
  filter(`#water_tech_category` == "Mechanized Pump")
```

### Extracting usage capacity of water points

In the code chunk below, `filter()` of dplyr is used to select water points with usage capacity \<1000 and \>=1000.

```{r}
#| eval: false
wpt_lowusage <- wp_sf %>%
  filter(usage_capacity < 1000)
```

```{r}
#| eval: false
wpt_highusage <- wp_sf %>%
  filter(usage_capacity >= 1000)
```

### Extracting rural water points

In the code chunk below, `filter()` of dplyr is used to select rural water points.

```{r}
#| eval: false
wpt_rural <- wp_sf %>%
  filter(is_urban == FALSE)
```

### Performing Point-in-Polygon Count

The code chunk below performs the point-in-polygon count of the respective fields.

```{r}
#| eval: false
nga_wp <- nga %>% 
  mutate(`total wpt` = lengths(
    st_intersects(nga, wp_sf))) %>%
  mutate(`wpt functional` = lengths(
    st_intersects(nga, wpt_functional))) %>%
  mutate(`wpt non-functional` = lengths(
    st_intersects(nga, wpt_nonfunctional))) %>%
  mutate(`wpt unknown` = lengths(
    st_intersects(nga, wpt_unknown)))%>%
  mutate(wpt_handbump = lengths(
    st_intersects(nga, wpt_handbump))) %>%
  mutate(wpt_mechanisdpump = lengths(
    st_intersects(nga, wpt_mechanisdpump))) %>%
  mutate(wpt_highusage = lengths(
    st_intersects(nga, wpt_highusage))) %>%
  mutate(wpt_lowusage = lengths(
    st_intersects(nga, wpt_lowusage))) %>%
  mutate(wpt_rural = lengths(
    st_intersects(nga, wpt_rural)))
```

### Computing Relevant Ratios of Water Points

The code chunk below uses `mutate()` of **dplyr** package to derive the respective percentage fields. Then, `is_na()` is used to replace all the *NaN* values in the percentage fields into *0*.

```{r}
#| eval: false
nga_wp <- nga_wp %>%
  mutate(pct_functional = `wpt functional`/`total wpt`) %>%
  mutate(`pct_non-functional` = `wpt non-functional`/`total wpt`) %>%
  mutate(pct_handpump = wpt_handbump/`total wpt`) %>%
  mutate(pct_mechanised = wpt_mechanisdpump/`total wpt`) %>%
  mutate(pct_highusage = wpt_highusage/`total wpt`) %>%
  mutate(pct_lowusage = wpt_lowusage/`total wpt`) %>%
  mutate(pct_rural = wpt_rural/`total wpt`)

nga_wp[is.na(nga_wp)] = 0
```

To review the summary statistics of *nga_wp*, we could use the code chunk below.

```{r}
#| eval: false
summary(nga_wp)
```

## Transforming of Projection

Using `st_crs()`，we could check the EPSG code of the data table. As it could be seen that the wrong EPSG code is used and we need to change it to 26391, which is the Projected Coordinate Systems of Nigeria.

```{r}
#| eval: false
nga_wp <- read_rds("geodata/nga_wp.rds")
st_crs(nga_wp)
```

```{r}
#| eval: false
nga_wp <- st_transform(nga_wp,26391)
st_crs(nga_wp)
```

## Saving the Analytical Data Table

The code chunk below saves the tidy sf data table into rds format for subsequent analysis.

```{r}
#| eval: false
write_rds(nga_wp, "geodata/nga_wp.rds")
```

## Exploratory Data Analysis (EDA)

### EDA using statistical graphics

The code chunk below plots the distribution of the numerical variables by using appropriate Exploratory Data Analysis (EDA). Histogram is chosen as it is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution).

First, I will create the individual histograms. Next, the [*ggarrange()*](https://rpkgs.datanovia.com/ggpubr/reference/ggarrange.html) function of [**ggpubr**](https://rpkgs.datanovia.com/ggpubr/) package is used to group these histograms together.

```{r,fig.width=10, fig.height=8}
nga_wp <- read_rds("geodata/nga_wp.rds")
wpt_func <- ggplot(data=nga_wp, 
             aes(x=`wpt functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

wpt_nonfunc <- ggplot(data=nga_wp, 
             aes(x= `wpt non-functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

wpt_pct_func <- ggplot(data=nga_wp, 
             aes(x=pct_functional)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

wpt_pct_nonfunc <- ggplot(data=nga_wp, 
             aes(x=`pct_non-functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

wpt_pct_handpump <- ggplot(data=nga_wp, 
             aes(x= pct_handpump)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

wpt_pct_mechanised <- ggplot(data=nga_wp, 
             aes(x= pct_mechanised)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

wpt_pct_high <- ggplot(data=nga_wp, 
             aes(x= pct_highusage)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

wpt_pct_low <- ggplot(data=nga_wp, 
             aes(x= pct_lowusage)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

wpt_pct_rural <- ggplot(data=nga_wp, 
             aes(x= pct_rural)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

ggarrange(wpt_func, wpt_nonfunc, wpt_pct_func, wpt_pct_nonfunc, wpt_pct_handpump, 
          wpt_pct_mechanised, wpt_pct_high, wpt_pct_low, wpt_pct_rural,
          ncol = 3, 
          nrow = 3)
```

**Observation:** It could be seen from the histograms that pct_functional seems to be the only variable that exhibit normal distribution. Other variables are more or less positively or negatively skewed. Particularly, wpt_functional is extremely positively skewed and pct_rural is extremely negatively skewed. Hence, we would need to perform **data standardisation** later before clustering to avoid biased clustering results.

### EDA using choropleth map

The code chunk below shows the spatial distribution of functional and non-functional waterpoint rate (%) at LGA level.

```{r}
percent_functional <- tm_shape(nga_wp) +
  tm_fill("pct_functional",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Distribution of Functional Waterpoints rate (%) at LGA level",
            main.title.position = "center",
            main.title.size = 0.7,
            legend.height = 0.2, 
            legend.width = 0.35)

percent_nonfunctional <- tm_shape(nga_wp) +
  tm_fill("pct_non-functional",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Distribution of Non-functional Waterpoints rate (%) at LGA level",
            main.title.position = "center",
            main.title.size = 0.7,
            legend.height = 0.2, 
            legend.width = 0.35)

tmap_arrange(percent_functional, 
             percent_nonfunctional, 
             asp=1, 
             ncol=2)
```

**Observation**: It could be seen that the waterpoint rates of both status (functional or non-functional) are not evenly distributed in Nigeria. Specifically, plenty of the counties at the northeastern region have high percentage of functional waterpoints. On the other hand, plenty of the counties at the southern region have high percentage of non-functional waterpoints.

## 

The code chunk below shows the spatial distribution of handpump and mechanised pump waterpoints (%) at LGA level.

```{r}
percent_handpump <- tm_shape(nga_wp) +
  tm_fill("pct_handpump",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Distribution of Handpump Waterpoints rate (%) at LGA level",
            main.title.position = "center",
            main.title.size = 0.7,
            legend.height = 0.2, 
            legend.width = 0.35)

percent_mechanisedpump <- tm_shape(nga_wp) +
  tm_fill("pct_mechanised",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Distribution of Mechanised Pump Waterpoints rate (%) at LGA level",
            main.title.position = "center",
            main.title.size = 0.7,
            legend.height = 0.2, 
            legend.width = 0.35)

tmap_arrange(percent_handpump, 
             percent_mechanisedpump, 
             asp=1, 
             ncol=2)
```

**Observation**: It could be seen that the Northern region of Nigeria has a high proportion of handpump waterpoints while the Southern region of Nigeria has a high proportion of mechanised pump waterpoints.

The code chunk below shows the spatial distribution of high usage and low usage waterpoints (%) at LGA level.

```{r}
percent_high <- tm_shape(nga_wp) +
  tm_fill("pct_highusage",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Distribution of High usage Waterpoints rate (%) at LGA level",
            main.title.position = "center",
            main.title.size = 0.7,
            legend.height = 0.2, 
            legend.width = 0.35)

percent_low <- tm_shape(nga_wp) +
  tm_fill("pct_lowusage",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Distribution of Low usage Waterpoints rate (%) at LGA level",
            main.title.position = "center",
            main.title.size = 0.7,
            legend.height = 0.2, 
            legend.width = 0.35)

tmap_arrange(percent_high, 
             percent_low, 
             asp=1, 
             ncol=2)
```

**Observation**: It could be seen that the Northern and Eastern region of Nigeria has a high proportion of low usage waterpoints while the Southern region of Nigeria has a high proportion of high usage waterpoints.

## Correlation Analysis

The code chunk below uses [*corrplot.mixed()*](https://cran.r-project.org/web/packages/corrplot/corrplot.pdf) function of [**corrplot**](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html) package to visualise and analyse the correlation of the input variables.

```{r}
nga_null <- nga_wp %>%
  st_set_geometry(NULL)
  
cluster_vars.cor = cor(nga_null[c(3:4, 11:17)])
corrplot.mixed(cluster_vars.cor,
               lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")
```

**Observation:**

It could be seen from the correlation plot that ***pct_mechanised*** and ***pct_highusage*** are highly positively correlated. Also, ***pct_handpump*** and ***pct_lowusage*** are highly positively correlated. On the other hand, ***pct_mechanised*** and ***pct_lowusage*** are highly negatively correlated. ***pct_lowusage*** and ***pct_highusage*** also have high negative correlation. Hence we would drop variable `pct_lowusage` for this exercise.

## Conventional Hierarchical Clustering

## Extracting clustering variables

The code chunk below will be used to extract the clustering variables from the *nga_wp* simple feature object into data.frame.

```{r}
cluster_vars <- nga_wp %>%
  st_set_geometry(NULL) %>%
  select("shapeName", "wpt functional", "wpt non-functional", "pct_functional", "pct_non-functional", "pct_handpump", "pct_mechanised","pct_highusage", "pct_rural")
head(cluster_vars,10)
```

As previously mentioned, we have excluded variable ***pct_lowusage*** because it is highly correlated with variable pct_handpump, pct_mechanised and pct_highusage.

Next, we need to change the rows by LGA name instead of row number by using the code chunk below.

```{r}
row.names(cluster_vars) <- cluster_vars$"shapeName"
head(cluster_vars,10)
```

Notice that the row number has been replaced into the LGA name. Now, we will delete the shapeName field by using the code chunk below.

```{r}
nga_wp_1 <- select(cluster_vars, c(2:9))
head(nga_wp_1, 10)
```

### Data Standardisation

In order to avoid the cluster analysis result being biased to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.

In the code chunk below, *normalize()* of [*heatmaply*](https://cran.r-project.org/web/packages/heatmaply/) package is used to standardization the clustering variables by using Min-Max method. The *summary()* is then used to display the summary statistics of the standardised clustering variables.

```{r}
nga_wp_1.std <- normalize(nga_wp_1)
summary(nga_wp_1.std)
```

We can see that the values range of the standardised clustering variables are 0-1 now.

### Computing proximity matrix

We will compute the proximity matrix by using [*dist()*](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/dist.html) of R and the code chunk below is used to compute the proximity matrix using *euclidean* method and list the content of *proxmat* for visual inspection.

```{r}
proxmat <- dist(nga_wp_1, method = 'euclidean')
```

### Selecting the optimal clustering algorithm

To identify stronger clustering structures, we can use [*agnes()*](https://www.rdocumentation.org/packages/cluster/versions/2.1.0/topics/agnes) function of [**cluster**](https://cran.r-project.org/web/packages/cluster/) package. It functions like *hclus()*, however, with the *agnes()* function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).

The code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.

```{r}
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

ac <- function(x) {
  agnes(nga_wp_1, method = x)$ac
}

map_dbl(m, ac)
```

It could be seen that Ward's method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward's method will be used.

### Determining Optimal Clusters

To determine the optimal clusters to retain, we could use the [**gap statistic**](http://www.web.stanford.edu/~hastie/Papers/gap.pdf) which compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). To compute the gap statistic, clusGap() of cluster package will be used.

```{r}
set.seed(12345)
gap_stat <- clusGap(nga_wp_1, 
                    FUN = hcut, 
                    nstart = 25, 
                    K.max = 10, 
                    B = 50)
# Print the result
print(gap_stat, method = "firstmax")
```

Next, we can visualise the plot by using [*fviz_gap_stat()*](https://rpkgs.datanovia.com/factoextra/reference/fviz_nbclust.html) of [**factoextra**](https://rpkgs.datanovia.com/factoextra/) package.

```{r}
fviz_gap_stat(gap_stat)
```

With reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 5-cluster gives the second largest gap statistic and should be the next best cluster to pick.

### Plotting the dendrograms

```{r}
hclust_ward <- hclust(proxmat, method = 'ward.D')
plot(hclust_ward, cex = 0.6)
rect.hclust(hclust_ward, 
            k = 5, 
            border = 2:5)
```

### Visually-driven hierarchical clustering analysis

#### Transforming the data frame into a matrix

The code chunk below will be used to transform *nga_wp_1* data frame into a data matrix to make the heatmap.

```{r}
nga_wp_1_mat <- data.matrix(nga_wp_1)
```

#### Plotting interactive cluster heatmap using *heatmaply()*

In the code chunk below, the [*heatmaply()*](https://talgalili.github.io/heatmaply/reference/heatmaply.html) of [heatmaply](https://talgalili.github.io/heatmaply/) package is used to build an interactive cluster heatmap.

```{r}
heatmaply(normalize(nga_wp_1_mat),
          Colv=NA,
          dist_method = "euclidean",
          hclust_method = "ward.D",
          seriate = "OLO",
          colors = Blues,
          k_row = 5,
          margins = c(NA,200,60,NA),
          fontsize_row = 4,
          fontsize_col = 5,
          main="Geographic Segmentation of Nigeria by waterpoint-related indicators",
          xlab = "Waterpoint-related Indicators",
          ylab = "LGAs of Nigeria"
          )
```

### Mapping the clusters formed

With closed examination of the dendragram above, we have decided to retain five clusters.

[*cutree()*](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/cutree.html) of R Base will be used in the code chunk below to derive a 5-cluster model.

```{r}
groups <- as.factor(cutree(hclust_ward, k=5))
```

The output is called *groups*. It is a *list* object. In order to visualise the clusters, the *groups* object need to be appended onto *nga_wp* simple feature object.

The code chunk below form the join in three steps:

-   the *groups* list object will be converted into a matrix;

-   *cbind()* is used to append *groups* matrix onto nga_wp to produce an output simple feature object called `nga_wp_cluster`; and

-   *rename* of **dplyr** package is used to rename *as.matrix.groups* field as *CLUSTER*.

```{r}
nga_wp_cluster <- cbind(nga_wp, as.matrix(groups)) %>%
  rename(`CLUSTER`=`as.matrix.groups.`)
```

Next, *qtm()* of **tmap** package is used to plot the choropleth map showing the cluster formed.

```{r}
qtm(nga_wp_cluster, "CLUSTER") + tm_layout(
  main.title = "Regionalisation of Nigeria using conventional hierarchical clustering",
  main.title.size = 0.8,
  main.title.position = "center")
```

**Observation**: It could be seen from the choropleth map that geographically-wise, the spatial distribution of the clusters is relatively fragmented with the exception of cluster 1. Most of the LGAs belong to cluster 1 are located at the NorthEastern and Southern region of Nigeria. The fragmented clusters make it very hard to implement large-scale regional efforts in terms of water point facilities as the LGAs have very different conditions with their nearby neighbors.

### Multivariate Visualisation

The code chunk below uses [`ggparcoord()`](https://ggobi.github.io/ggally/reference/ggparcoord.html) of [**GGally**](https://ggobi.github.io/ggally/) package to draw parallel coordinate plot and reveal clustering variables by cluster.

```{r}
ggparcoord(data = nga_wp_cluster, 
           columns = c(11:17), 
           scale = "globalminmax",
           alphaLines = 0.2,
           groupColumn = "CLUSTER",
           boxplot = TRUE, 
           title = "Multiple Parallel Coordinates Plots of Nigeria LGAs by Cluster") +
  scale_color_viridis(discrete=TRUE) + 
  facet_grid(~ CLUSTER) + 
  theme(axis.text.x = element_text(angle = 90))
```

**Observation:** It could be seen from plot that the cluster 2 has a high proportion of non-functional and rural water points. Hence, more efforts should be directed towards the LGAs belonging to this cluster.

## Spatially Constrained Clustering using SKATER approach

### Converting into SpatialPolygonsDataFrame

The code chunk below uses [*as_Spatial()*](https://r-spatial.github.io/sf/reference/coerce-methods.html) of **sf** package to convert *nga_wp* into a SpatialPolygonDataFrame called *nga_wp_sp* as SKATER function only support **sp** objects such as SpatialPolygonDataFrame.

```{r}
nga_sp <- as_Spatial(nga_wp)
```

### Computing Neighbour List

Next, *st_centroid()* function is used to retrieve the polygon centroid and *knn2nb()* function will be used to compute the neighbours list using k-nearest neighbors from polygon list.

```{r}
coords <- st_centroid(st_geometry(nga_wp))
knn <- knn2nb(knearneigh(coords, k = 8))
summary(knn)
```

We can plot the neighbours list on nga_sp by using the code chunk below.

```{r}
plot(nga_sp, 
     border=grey(.5))
plot(knn, 
     coordinates(nga_sp), 
     col="blue", 
     add=TRUE)
```

### **Computing Minimum Spanning Tree**

#### **Calculate edge costs**

[*nbcosts()*](https://r-spatial.github.io/spdep/reference/nbcosts.html) of **spdep** package is used to compute the cost of each edge. It is the distance between it nodes. This function compute this distance using a data.frame with observations vector in each node.

The code chunk below is used to compute the cost of each edge.

```{r}
lcosts <- nbcosts(knn, nga_wp_1)
```

Then we use the [*nb2listw()*](https://r-spatial.github.io/spdep/reference/nb2listw.html) of **spdep** package to convert the neighbour list to a list weights object by specifying the just computed ***lcosts*** as the weights.

```{r}
nga.w <- nb2listw(knn, 
                   lcosts, 
                   style="B")
summary(nga.w)
```

### Computing minimum spanning tree

The minimum spanning tree is computed by mean of the [*mstree()*](https://r-spatial.github.io/spdep/reference/mstree.html) of **spdep** package as shown in the code chunk below.

```{r}
nga.mst <- mstree(nga.w)
```

After computing the MST, the code chunk below checks its class and dimension.

```{r}
class(nga.mst)
```

The code chunk below displays the content of *nga.mst* by using *head()*.

```{r}
head(nga.mst)
```

The code chunk below plots this together with the LGA boundaries.

```{r}
plot(nga_sp, border=gray(.5))
plot.mst(nga.mst, 
         coordinates(nga_sp), 
         col="blue", 
         cex.lab=0.7, 
         cex.circles=0.005, 
         add=TRUE)
```

### Computing spatially constrained clusters using SKATER method

The code chunk below compute the spatially constrained cluster using [*skater()*](https://r-spatial.github.io/spdep/reference/skater.html) of **spdep** package.

```{r}
clust5 <- skater(edges = nga.mst[,1:2], 
                 data = nga_wp_1, 
                 method = "euclidean", 
                 ncuts = 4)
```

The result of the *skater()* is an object of class **skater**. The code chunk below examines its contents.

```{r}
str(clust5)
```

The code chunk below checks the cluster assignment.

```{r}
ccs5 <- clust5$groups
ccs5
```

The code chunk below finds out how many observations are in each cluster by means of the table command.

```{r}
table(ccs5)
```

Lastly, the code chunk below plots the pruned tree that shows the five clusters on top of the LGA area.

```{r}
plot(nga_sp, border=gray(.5))
plot(clust5, 
     coordinates(nga_sp), 
     cex.lab=.7,
     groups.colors=c("red","green","blue", "brown", "pink"),
     cex.circles=0.005, 
     add=TRUE)
```

### Visualising the clusters in choropleth map

The code chunk below is used to plot the newly derived clusters by using SKATER method.

```{r}
groups_mat <- as.matrix(clust5$groups)
nga_sf_spatialcluster <- cbind(nga_wp_cluster, as.factor(groups_mat)) %>%
  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)
qtm(nga_sf_spatialcluster, "SP_CLUSTER")
```

For easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other. This could be achieved by using the code chunk below.

```{r}
hclust.map <- qtm(nga_wp_cluster,
                  "CLUSTER") + 
  tm_borders(alpha = 0.5) + 
  tm_layout(main.title = "Regionalisation of Nigeria using hierarchical clustering",
            main.title.position = "center",
            main.title.size = 0.7,
            legend.height = 0.2, 
            legend.width = 0.35)

shclust.map <- qtm(nga_sf_spatialcluster,
                   "SP_CLUSTER") + 
  tm_borders(alpha = 0.5) + 
  tm_layout(main.title = "Regionalisation of Nigeria using spatially constrained clustering",
            main.title.position = "center",
            main.title.size = 0.7,
            legend.height = 0.2, 
            legend.width = 0.35)

tmap_arrange(hclust.map, shclust.map,
             asp=NA, ncol=2)
```

**Observation:** It could be seen from the choropleth map that as compared to hierarchical clustering, the clusters formed under spatially constrained clustering method are more closely located and concentrated. As such, regional infrastructure improvement towards water points according to spatially constrained clustering would be more easier to implement and probably more effective as LGAs would have similar conditions with their nearby neighbors. Hence, large-scale facilities could be shared among these LGAs as they are in geographical proximity.

## Visual Interpretation of Clusters

### Multivariate Visualisation

The code chunk below uses [`ggparcoord()`](https://ggobi.github.io/ggally/reference/ggparcoord.html) of [**GGally**](https://ggobi.github.io/ggally/) package to draw parallel coordinate plot and reveal clustering variables by cluster.

```{r}
ggparcoord(data = nga_sf_spatialcluster, 
           columns = c(11:17), 
           scale = "globalminmax",
           alphaLines = 0.2,
           groupColumn = "SP_CLUSTER",
           boxplot = TRUE, 
           title = "Multiple Parallel Coordinates Plots of Nigeria LGAs by Cluster") +
  scale_color_viridis(discrete=TRUE) + 
  facet_grid(~ SP_CLUSTER) + 
  theme(axis.text.x = element_text(angle = 90))
```

**Observation:** It could be seen from plot that the cluster 1 has a relatively high proportion of non-functional and high usage water points. Hence, more efforts should be directed towards the maintenance of the waterpoints at the LGAs belonging to this cluster as these waterpoints are in high usage and if they are not functioning properly, many people would be affected.
